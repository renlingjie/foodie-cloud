#1、端口
server:
  port: 10007
#2、数据源改动
spring:
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    # 数据源的相关配置(微服务注意：每个服务都应该有对应的数据源)
    url: ${datasource.url}
    password: ${datasource.password}
    username: ${datasource.username}
  redis:
    database: 1   #database数量，16以内，默认是0
    host: 82.156.233.44
    port: 6379
    timeout: 500
    # password: rlj   #Redis所在主机的配置文件中配置的密码
  # Bus总线的消息队列连接信息
  rabbitmq:
    host: 152.136.220.204
    port: 5672
    username: admin
    password: 123
  # ES连接信息，配置ES集群名称和集群下的节点，这里就一个，节点之间用的是TCP(ES对应9300)
  data:
    elasticsearch:
      cluster-name: rlj-elasticsearch
      cluster-nodes: 43.138.12.238:9300
  # actuator对ES健康检查会报错Connection refused，所以需要指定节点的Http(ES对应9200)连接信息
  # 或者直接关闭对ES的健康检查：management.health.elasticsearch.enabled=false
  elasticsearch:
    rest:
      uris: ["http://43.138.12.238:9200"]
  # Sleuth+Zipkin，完成对User微服务的日志的埋点，并将日志发送给Zipkin统计、展示
  # !!!因为一旦模块使用Bus刷新配置，依赖引入了bus-amqp，Sleuth智能的识别出来了，然后将默认的通过Web给Zipkin发送日志
  # 的方式换成RabbitMq了，这样Zipkin默认是使用Web接收的，自然接收不到任何信息。所以这里指定Sleuth发送方式为Web
  zipkin:
    discovery-client-enabled: true
    # Zipkin通过Eureka高可用后，可以通过服务发现来定位，这样base-url就不用写具体的IP了
    base-url: http://ZIPKIN-SERVER/
    locator:
      discovery:
        enabled: true
    # Sleuth以Web(Http)的形式给Zipkin发送日志
    sender:
      type: web
  sleuth:
    sampler:
      probability: 1  # 采样率设置为1

#3、开发环境我们的日志打印照旧
mybatis:
  configuration:
    log-impl: org.apache.ibatis.logging.stdout.StdOutImpl #在控制台输出日志的实现
#4、开启actuator，暴露信息以供hystrix的turbine接收--统一放到了Gitee中
